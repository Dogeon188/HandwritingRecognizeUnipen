{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import keras\n",
    "from utils.preprocess import *\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = load_unipen_dataset(no_cap)\n",
    "\n",
    "# normalize dataset\n",
    "def normalize(data, label):\n",
    "    return tf.cast(data, tf.float32) / 255.0, label\n",
    "\n",
    "if normalize_dataset:\n",
    "    dataset = dataset.map(normalize)\n",
    "dataset = dataset.shuffle(10000).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "target_model = \"unipen_no_cap_model\" if no_cap else \"unipen_model\"\n",
    "model = keras.models.load_model(f\"data/{target_model}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict all\n",
    "loss, acc = model.evaluate(dataset)\n",
    "print(\"Overall loss:    \", loss)\n",
    "print(\"Overall accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# Get the outputs of all layers\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "\n",
    "# Create a new model that outputs the outputs of all layers\n",
    "model_all_outputs = Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "# Initialize lists to keep track of the largest and smallest values for each layer\n",
    "max_value = float(\"-inf\")\n",
    "min_value = float(\"inf\")\n",
    "\n",
    "# Predict with the new model\n",
    "outputs = model_all_outputs.predict(dataset.take(100))\n",
    "\n",
    "# Loop through each output in outputs\n",
    "for output in outputs:\n",
    "    # Loop through each layer\n",
    "    for layer_index, layer in enumerate(output):\n",
    "        # Find the largest value in the layer\n",
    "        layer_max = np.max(layer)\n",
    "        # Find the smallest value in the layer\n",
    "        layer_min = np.min(layer)\n",
    "        # Update the max and min values for this layer if it's greater or less than the current max or min\n",
    "        max_value = max(layer_max, max_value)\n",
    "        min_value = min(layer_min, min_value)\n",
    "\n",
    "# Print the largest and smallest values for each layer\n",
    "print(\"Max:\", max_value)\n",
    "print(\"Min:\", min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict & plot\n",
    "from utils.demonstration import plot_digits\n",
    "\n",
    "for img, label in dataset.take(1):\n",
    "    prediction = model.predict(img, verbose=0)\n",
    "    plot_digits(img.numpy(), label.numpy(), prediction, (8, 8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unipen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
